{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Welcome to our project report! ‚ú®üß™**\n",
    "## üöÄ *Overview*\n",
    "This notebook presents an analysis of our pKa prediction package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§Ø *Acquiring Dataset*\n",
    "In a first step, we will acquire the [pKa dataset](https://github.com/cbio3lab/pKa/blob/main/Data/test_acids_bases_descfinal_nozwitterions.csv) from cbio3lab's repository, initially extracted from the Harvard [dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/6A67L9).\n",
    "\n",
    "Next, we will perform an exploratory analysis of the collected dataset.\n",
    "\n",
    "1) Let's download the data directly into your working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File downloaded successfully: pkadatasetRAWDATA.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Correct raw file URL\n",
    "url = \"https://raw.githubusercontent.com/anastasiafloris/pKaPredict/main/data/pkadatasetRAWDATA.csv\"\n",
    "file_name = \"pkadatasetRAWDATA.csv\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error if the request fails\n",
    "\n",
    "    # Check if the content is an HTML page (meaning it's the wrong link)\n",
    "    if \"<!DOCTYPE html>\" in response.text:\n",
    "        print(\"‚ùå Error: This is an HTML page, not the CSV file. Check your URL.\")\n",
    "    else:\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"‚úÖ File downloaded successfully: {file_name}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Failed to download file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Let's open the file and verify its existence as well as display a preview of the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/anastasiafloris/Desktop/pKaPredict/pKaPredict/notebooks\n",
      "The dataset file exists. Reading the file contents...\n",
      "\n",
      "Compound,set,Smiles,pka,prot_smiles,deprot_smiles,acid_base_type,acid_base_string,prot_charge,deprot_charge,CH_strength,XH_strength,HBA_strength,Hyd_Apolar,Hyd_Polar,Hyd,CCCC,NCCC,CCNC,CCCO,CCNN,NCCN,CNNC,CNCN,NCCO,CNCO,CNNN,NCNN,OCNN,CCSO,NCSO,nA,nR,nN,nD,nC,nF,nQ,nE,nG,nH,nI,nP,nL,nK,nM,nS,nT,nY,nV,nW,BCUTw.1l,BCUTw.1h,BCUTc.1l,BCUTc.1h,BCUTp.1l,BCUTp.1h,Fsp3,XLogP,MW,LipinskiFailures,nRotB,MLogP,nAtomLAC,nAtomP,nAtomLC,nB,nBase,nAtom,nAromBond,naAromAtom,ALogP,ALogp2,AMR,nAcid,nSmallRings,nAr\n",
      "\n",
      "Dataset successfully loaded. Preview:\n",
      "   Compound   set                             Smiles    pka  \\\n",
      "0         4  test            Brc1ccc(-c2nn[nH]n2)cc1   3.73   \n",
      "1         6  test                Brc1ccc(C2NCCS2)cc1   5.05   \n",
      "2         7  test  Brc1ccc(Cc2c3ccccc3nc3ccccc23)cc1   7.00   \n",
      "3        18  test  Brc1cccc(Br)c1N(C1=NCCN1)C1CCCCC1  11.30   \n",
      "4        21  test  Brc1cccc(Br)c1N(CC1CCCC1)C1=NCCN1  10.90   \n",
      "\n",
      "                             prot_smiles                      deprot_smiles  \\\n",
      "0                Brc1ccc(-c2nn[nH]n2)cc1            Brc1ccc(-c2nn[n-]n2)cc1   \n",
      "1                    Brc1ccc(C2NCCS2)cc1           Brc1ccc(C2[NH2+]CCS2)cc1   \n",
      "2  Brc1ccc(Cc2c3ccccc3[nH+]c3ccccc23)cc1  Brc1ccc(Cc2c3ccccc3nc3ccccc23)cc1   \n",
      "3  Brc1cccc(Br)c1N(C1=[NH+]CCN1)C1CCCCC1  Brc1cccc(Br)c1N(C1=NCCN1)C1CCCCC1   \n",
      "4  Brc1cccc(Br)c1N(CC1CCCC1)C1=[NH+]CCN1  Brc1cccc(Br)c1N(CC1CCCC1)C1=NCCN1   \n",
      "\n",
      "  acid_base_type acid_base_string  prot_charge  deprot_charge  ...  \\\n",
      "0         acidic                A            0             -1  ...   \n",
      "1          basic                B            1              0  ...   \n",
      "2          basic                B            1              0  ...   \n",
      "3          basic                B            1              0  ...   \n",
      "4          basic                B            1              0  ...   \n",
      "\n",
      "        ATSm5     ATSc1     ATSc2     ATSc3     ATSc4     ATSc5  nHBDon  \\\n",
      "0   16.982131  0.092406 -0.049547  0.007228  0.005439  0.003309       1   \n",
      "1   19.324610  0.106754 -0.072082  0.017678  0.005596  0.000479       1   \n",
      "2   37.151221  0.092960 -0.041298 -0.013032  0.016142 -0.007716       0   \n",
      "3  111.835963  0.239813 -0.173828  0.098983 -0.044103 -0.071317       1   \n",
      "4  108.669781  0.241317 -0.177460  0.105635 -0.051910 -0.065520       1   \n",
      "\n",
      "   nHBAcc       bpol       apol  \n",
      "0       3   7.416035  23.103965  \n",
      "1       1  15.162070  29.557930  \n",
      "2       1  17.914898  48.685102  \n",
      "3       3  27.310933  48.469067  \n",
      "4       3  27.310933  48.469067  \n",
      "\n",
      "[5 rows x 274 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the current working directory\n",
    "current_directory = Path.cwd()\n",
    "print(\"Current Directory:\", current_directory.resolve())\n",
    "\n",
    "# Specify the path to the dataset file\n",
    "file_path = current_directory / \"pkadatasetRAWDATA.csv\"\n",
    "\n",
    "# Verify the file's existence and read its contents if available\n",
    "if file_path.exists():\n",
    "    print(\"The dataset file exists. Reading the file contents...\\n\")\n",
    "    \n",
    "    # Open and display the contents (optional, for verification)\n",
    "    with file_path.open(\"r\") as file:\n",
    "        content = file.read()\n",
    "        print(content[:500])  # Print only the first 500 characters for preview\n",
    "    \n",
    "    # Load the dataset using pandas\n",
    "    try:\n",
    "        data_pka = pd.read_csv(file_path, delimiter=\",\")  # Adjust delimiter if necessary\n",
    "        print(\"\\nDataset successfully loaded. Preview:\")\n",
    "        print(data_pka.head())  # Display first few rows\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: The specified file does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ *Cleaning Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Prints initial dataset shape <br> \n",
    "‚úÖ Counts and removes missing values (NaN)  <br>\n",
    "‚úÖ Prints final dataset shape after cleaning  <br>\n",
    "‚úÖ Generates a histogram to visualize pKa value distribution  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remove missing values and check dataset shape\n",
    "def clean_and_visualize_pka(data_pka):\n",
    "    \"\"\"Cleans dataset by removing NaN values and visualizes pKa distribution.\"\"\"\n",
    "    \n",
    "    # Check initial shape\n",
    "    initial_shape = data_pka.shape\n",
    "    print(f\"Initial dataset shape: {initial_shape}\")\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = data_pka.isnull().sum().sum()\n",
    "    print(f\"Total missing values: {missing_values}\")\n",
    "\n",
    "    # Drop NaN values\n",
    "    data_pka.dropna(inplace=True)\n",
    "\n",
    "    # Check final shape after cleaning\n",
    "    final_shape = data_pka.shape\n",
    "    print(f\"Dataset shape after NaN removal: {final_shape}\")\n",
    "\n",
    "    # Generate histogram for pKa distribution\n",
    "    print(\"\\nGenerating histogram for pKa distribution...\\n\")\n",
    "    sns.set_theme()\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data=data_pka, x=\"pka\", binwidth=0.5, kde=True)\n",
    "    plt.xlabel(\"pKa\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of pKa Values\")\n",
    "    plt.show()\n",
    "\n",
    "    return data_pka  # Return cleaned dataset for further processing if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pKaPredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
